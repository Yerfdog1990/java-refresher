
---

# **3.1: Big-O Notation**

Big-O notation is one of the most important tools in algorithm analysis. It helps us understand how fast a function grows, especially when the input size becomes very large. In algorithm analysis, Big-O describes **how the running time or memory usage of an algorithm increases as the input size (n) increases.**

---

## âœ… **1. What Is Big-O? (Simple Definition)**

Big-O notation gives an **upper bound** on the growth of a function.
It answers the question:

> â€œHow fast does this algorithm grow in the worst case as n becomes very large?â€

We compare two functionsâ€”say **f(n)** and **g(n)**â€”and say:

```
f(n) = O(g(n))
```

This means:

* **f(n) grows no faster than g(n)** (up to a constant factor)
* For sufficiently large n,
  `f(n) â‰¤ A * g(n)` for some constant `A > 0`

It is a way of saying:
**â€œf(n) is at most as big as g(n), ignoring constant factors.â€**

---

## âœ… **2. Formal Definition (Beginner-Friendly)**

We say:

```
f(n) = O(g(n))
```

if:

* f(n) and g(n) are positive functions
* There exist constants **A > 0** and **nâ‚€ > 0**
* Such that for all `n â‰¥ nâ‚€`:

```
f(n) â‰¤ A * g(n)
```

This means **the ratio f(n)/g(n) is bounded**.

In plain words:

> If f(n) grows no faster than some constant times g(n), then f(n) is O(g(n)).

---

## âœ… **3. Example: Proving f(n) = O(nÂ²)**

Let:

```
f(n) = 100nÂ² + 10n + 1
g(n) = nÂ²
```

Compute:

```
f(n)/g(n) = (100nÂ² + 10n + 1) / nÂ²
          = 100 + 10/n + 1/nÂ²
```

Observations:

* `10/n` gets smaller as n increases
* `1/nÂ²` also gets smaller

For all `n â‰¥ 1`, we have:

```
10/n â‰¤ 10
1/nÂ² â‰¤ 1
```

So:

```
f(n)/g(n) â‰¤ 100 + 10 + 1 = 111
```

This satisfies the Big-O condition:

```
f(n) â‰¤ 111 * nÂ²
```

Therefore:

```
f(n) = O(nÂ²)
```

---

## âœ… **4. What Does This Mean?**

This does **NOT** mean the two functions are identical.

It means:

* f(n) **grows at most quadratically**
* As n becomes large, the dominating term is `100nÂ²`
* Lower-order terms like `10n` and `1` become insignificant

Even though f(n) has extra terms, it still belongs to the same *growth class* as nÂ².

---

## â— A common beginner confusion

You may think:
â€œWait, f(n) grows **100 times faster**, how is that considered similar?â€

Because in asymptotic notation:

> **Constant factors do not matter.**

We only care about the growth *trend*, not the exact values.

---

## ğŸš« When Big-O Does NOT Hold

Let:

```
h(n) = nÂ² log n
g(n) = nÂ²
```

Compute:

```
h(n)/g(n) = log n
```

As n â†’ âˆ:

```
log n â†’ âˆ
```

This ratio is **not bounded**, therefore:

```
h(n) â‰  O(nÂ²)
```

Because `nÂ² log n` grows **faster** than `nÂ²`.

---

## âœ… **5. Important Property**

If:

```
f(n) = O(g(n))
and
g(n) = O(h(n))
```

Then:

```
f(n) = O(h(n))
```

This is called **transitivity**.

Example:

```
nÂ² = O(nÂ³)
nÂ³ = O(nâ´)
â†’ nÂ² = O(nâ´)
```

---

## â­ Big-O vs Big-Theta (for clarity)

In algorithm discussions, people sometimes say:

> â€œThe algorithm is O(nÂ²)â€

when they really mean:

> â€œThe algorithm grows *like* nÂ²,â€
> which is actually **Î˜(nÂ²)** (tight bound)

But Big-O is often used informally.

---

## âœ… **6. How Big-O Is Used in Algorithm Analysis**

Big-O is used to classify:

### **Time Complexity**

How many operations an algorithm performs.

Example:

* A loop from 1 to n â†’ O(n)
* A nested loop â†’ O(nÂ²)
* Binary search â†’ O(log n)

### **Space Complexity**

How much memory an algorithm needs.

Example:

* Using an array of size n â†’ O(n)
* Using only a few variables â†’ O(1)

---

## â­ Typical Use in Practice

When we say â€œan O(nÂ²) algorithm,â€ we mean:

* It performs at most a quadratic number of operations.
* Its growth is similar to nÂ² (up to a constant factor).
* For large n, lower-order terms donâ€™t matter.

---

## ğŸ§  Quick Notes for Beginners

* Faster growth â†’ **slower algorithm**
* O(n) is **better** (faster) than O(nÂ²)
* Constant factors (like 100nÂ²) do not matter
* Always analyze the **dominant term**

---

## ğŸ“Œ Summary

Big-O notation helps us:

* Understand algorithm efficiency
* Compare different algorithms
* Ignore constant factors and small details
* Focus on long-term performance behavior

**The goal is to classify algorithms into broad speed groups (constant, linear, quadratic, etc.).**

---


